{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 30 09:46:45 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 566.41       CUDA Version: 12.7     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce MX130            On | 00000000:02:00.0 Off |                  N/A |\n",
      "| N/A    0C    P5               N/A / 200W|    132MiB /  2048MiB |     29%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
    "version_str=\"\".join([\n",
    "    f\"py3{sys.version_info.minor}_cu\",\n",
    "    torch.version.cuda.replace(\".\",\"\"),\n",
    "    f\"_pyt{pyt_version_str}\"\n",
    "])\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 100,
     "status": "ok",
     "timestamp": 1753601420375,
     "user": {
      "displayName": "Ayotunde Ajayi",
      "userId": "17952995612212148316"
     },
     "user_tz": -60
    },
    "id": "B7Y2pCiokNgP",
    "outputId": "88291119-2e89-4832-ee3a-c0f4a373e4c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sys' (built-in)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import gc\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import zipfile\n",
    "import urllib\n",
    "import pathlib\n",
    "\n",
    "base_url = pathlib.Path().resolve()\n",
    "\n",
    "sys.path.append(f\"{base_url}/GauHuman\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "importlib.reload(sys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "87VgYhiYfqp4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/noble/miniconda3/envs/gauhuman/lib/python3.8/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "*************** EP Error ***************\n",
      "EP Error /onnxruntime_src/onnxruntime/python/onnxruntime_pybind_state.cc:490 void onnxruntime::python::RegisterTensorRTPluginsAsCustomOps(PySessionOptions&, const onnxruntime::ProviderOptions&) Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
      " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.\n",
      "****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m2025-07-29 12:38:49.421774710 [E:onnxruntime:Default, provider_bridge_ort.cc:1978 TryGetProviderInfo_TensorRT] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1637 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_tensorrt.so with error: libcudnn.so.9: cannot open shared object file: No such file or directory\n",
      "\u001b[m\n",
      "\u001b[1;31m2025-07-29 12:38:50.015576750 [E:onnxruntime:Default, provider_bridge_ort.cc:1992 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1637 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.12: cannot open shared object file: No such file or directory\n",
      "\u001b[m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sparse import Spare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxTTKWlRNU74"
   },
   "outputs": [],
   "source": [
    "s = Spare(1.7272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11585,
     "status": "ok",
     "timestamp": 1753524621278,
     "user": {
      "displayName": "Ayotunde Ajayi",
      "userId": "17952995612212148316"
     },
     "user_tz": -60
    },
    "id": "MBErQ7pXqKEF",
    "outputId": "093602bf-4365-462a-fba2-9c89b180c29c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading video with torchvision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 30/30 [00:02<00:00, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Finished. Selected and saved 31 frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s.video_to_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y72hC0JVPCwI"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GzbGINMho_vE"
   },
   "outputs": [],
   "source": [
    "pcd = o3d.io.read_point_cloud(f\"{dense_path}/dense.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRe9KJrjrqkV"
   },
   "outputs": [],
   "source": [
    "points = np.array([p.xyz for p in recon.points3D.values()])\n",
    "len(points)\n",
    "colors = np.array([p.color / 255.0 for p in recon.points3D.values()])  # normalize RGB to [0, 1]\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kb31iEVRoqdx"
   },
   "outputs": [],
   "source": [
    "points = np.asarray(pcd.points)\n",
    "colors = None\n",
    "if pcd.has_colors():\n",
    "    colors = np.asarray(pcd.colors)\n",
    "elif pcd.has_normals():\n",
    "    colors = (0.5, 0.5, 0.5) + np.asarray(pcd.normals) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5AyN19Afnyg"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=points[:, 0], y=points[:, 1], z=points[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(size=1, color=colors, opacity=0.8)\n",
    "        )\n",
    "    ],\n",
    "    layout=go.Layout(\n",
    "        width=1000,  # Large figure width\n",
    "        height=800,  # Large figure height\n",
    "        margin=dict(l=0, r=0, b=0, t=0),  # Remove padding\n",
    "        scene=dict(\n",
    "            xaxis=dict(visible=False),\n",
    "            yaxis=dict(visible=False),\n",
    "            zaxis=dict(visible=False),\n",
    "            aspectmode='data',  # keeps real proportions\n",
    "            bgcolor='white'     # bright background\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7c25b083"
   },
   "outputs": [],
   "source": [
    "!conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
    "!conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1753174178402,
     "user": {
      "displayName": "Ayotunde",
      "userId": "09413824836506977049"
     },
     "user_tz": -60
    },
    "id": "a0d4de24",
    "outputId": "cb9c9ac1-1119-49d3-c704-7a4c783773ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base.py  config.py  constants.py  inference.py\t__pycache__  test.py  train.py\n"
     ]
    }
   ],
   "source": [
    "!ls /content/drive/MyDrive/SmartAr/smplestx/main"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "smart_ar_eva",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
